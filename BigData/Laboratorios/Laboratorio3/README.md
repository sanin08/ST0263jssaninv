# Titulo

Laboratorio 2 Bigdata

# Autor

Juan Sebastián Sanín Villarreal

# Descripción

Implementación del Wordcount en Apache Spark de diferentes opciones.
 
 # Resultados
 
## 1. Ejecutar el wordcount por linea de comando 'pyspark' INTERACTIVO en EMR con datos en HDFS vía ssh en el nodo master.

**R/**

![](https://i.ibb.co/pbQ4DBs/HDFS.png)

**Archivos**

![](https://i.ibb.co/NS2HZy2/Archivos.png)

## 2. Ejecutar el wordcount por linea de comando 'pyspark' INTERACTIVO en EMR con datos en S3 (tanto de entrada como de salida)  vía ssh en el nodo master.
**Archivos en S3**

![](https://i.ibb.co/3yhQrrj/Archivos-en-S3.png)

**R/**

![](https://i.ibb.co/Jm4kj38/S3.png)

## 3. Ejecutar el wordcount en JupyterHub Notebooks EMR con datos en S3 (tanto datos de entrada como de salida) usando un clúster EMR.

**R/**

![](https://i.ibb.co/R7q2pyT/Jupyter.png)

**Aquí podemos ver el guardado de lo anterior en S3**

![](https://i.ibb.co/KwBFC1d/Guardado.png)

# Parte 2

## Replique, ejecute y ENTIENDA el notebook: Data_processing_using_PySpark.ipynb con los datos respectivos. ejecutelo en AWS EMR.

### Datos en el bucket: s3://datasetsjssaninv/datasets/spark/

**Archivo con replicación, ejecución y entendimiento:** [Datos](https://github.com/sanin08/ST0263jssaninv/blob/main/BigData/Laboratorios/Laboratorio3/Laboratorio3.ipynb) 
  
